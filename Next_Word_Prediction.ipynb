{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9UwhvUWVVGaLw5D/pcneh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryavamshi866/Next_Word_Prediction/blob/main/Next_Word_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3AXV_Acxf6UF"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "RkwfbFPug4xF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "aWEHh8JwiCPA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "k_qGvq87iGw8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5HOLoLSiMp8",
        "outputId": "de6c8f2b-fa77-4ffa-8fd4-ac1e74752331"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'you': 2,\n",
              " 'i': 3,\n",
              " 'to': 4,\n",
              " 'a': 5,\n",
              " 'of': 6,\n",
              " 'is': 7,\n",
              " 'have': 8,\n",
              " 'will': 9,\n",
              " 'can': 10,\n",
              " 'what': 11,\n",
              " 'course': 12,\n",
              " 'program': 13,\n",
              " 'in': 14,\n",
              " 'for': 15,\n",
              " 'all': 16,\n",
              " 'sessions': 17,\n",
              " 'on': 18,\n",
              " 'be': 19,\n",
              " 'and': 20,\n",
              " 'this': 21,\n",
              " 'if': 22,\n",
              " 'am': 23,\n",
              " 'pay': 24,\n",
              " 'payment': 25,\n",
              " 'make': 26,\n",
              " 'we': 27,\n",
              " 'do': 28,\n",
              " 'subscription': 29,\n",
              " 'where': 30,\n",
              " 'rs': 31,\n",
              " 'so': 32,\n",
              " 'campusx': 33,\n",
              " 'session': 34,\n",
              " 'our': 35,\n",
              " 'paid': 36,\n",
              " 'join': 37,\n",
              " 'able': 38,\n",
              " 'your': 39,\n",
              " 'website': 40,\n",
              " 'placement': 41,\n",
              " 'fee': 42,\n",
              " 'data': 43,\n",
              " 'monthly': 44,\n",
              " 'month': 45,\n",
              " 'not': 46,\n",
              " 'get': 47,\n",
              " 'yes': 48,\n",
              " 'once': 49,\n",
              " 'past': 50,\n",
              " 'feb': 51,\n",
              " 'assistance': 52,\n",
              " 'science': 53,\n",
              " '7': 54,\n",
              " '5600': 55,\n",
              " 'are': 56,\n",
              " 'watch': 57,\n",
              " 'google': 58,\n",
              " 'by': 59,\n",
              " 'com': 60,\n",
              " 'mail': 61,\n",
              " 'from': 62,\n",
              " 'contact': 63,\n",
              " 'us': 64,\n",
              " 'at': 65,\n",
              " 'or': 66,\n",
              " 'doubt': 67,\n",
              " 'mentorship': 68,\n",
              " 'payments': 69,\n",
              " '799': 70,\n",
              " 'total': 71,\n",
              " 'duration': 72,\n",
              " 'months': 73,\n",
              " 'learning': 74,\n",
              " 'case': 75,\n",
              " 'here': 76,\n",
              " 'https': 77,\n",
              " 'part': 78,\n",
              " 'see': 79,\n",
              " 'late': 80,\n",
              " 'dashboard': 81,\n",
              " 'task': 82,\n",
              " 'don’t': 83,\n",
              " 'nitish': 84,\n",
              " 'validity': 85,\n",
              " '15th': 86,\n",
              " 'jan': 87,\n",
              " 'period': 88,\n",
              " 'after': 89,\n",
              " 'till': 90,\n",
              " '21st': 91,\n",
              " 'that': 92,\n",
              " 'about': 93,\n",
              " 'follows': 94,\n",
              " 'model': 95,\n",
              " 'syllabus': 96,\n",
              " 'python': 97,\n",
              " 'ml': 98,\n",
              " 'studies': 99,\n",
              " 'learnwith': 100,\n",
              " 'deep': 101,\n",
              " 'nlp': 102,\n",
              " 'no': 103,\n",
              " 'miss': 104,\n",
              " 'live': 105,\n",
              " 'recording': 106,\n",
              " 'even': 107,\n",
              " 'class': 108,\n",
              " 'time': 109,\n",
              " '2': 110,\n",
              " 'how': 111,\n",
              " 'absolutely': 112,\n",
              " 'middle': 113,\n",
              " 'anytime': 114,\n",
              " 'submit': 115,\n",
              " 'with': 116,\n",
              " 'gmail': 117,\n",
              " 'registration': 118,\n",
              " 'related': 119,\n",
              " 'link': 120,\n",
              " 'entire': 121,\n",
              " 'suppose': 122,\n",
              " 'again': 123,\n",
              " 'days': 124,\n",
              " 'day': 125,\n",
              " 'refund': 126,\n",
              " 'living': 127,\n",
              " 'outside': 128,\n",
              " 'india': 129,\n",
              " 'should': 130,\n",
              " 'sending': 131,\n",
              " 'queries': 132,\n",
              " 'videos': 133,\n",
              " 'read': 134,\n",
              " 'but': 135,\n",
              " 'provided': 136,\n",
              " 'form': 137,\n",
              " '1': 138,\n",
              " 'clearance': 139,\n",
              " 'week': 140,\n",
              " 'just': 141,\n",
              " 'certificate': 142,\n",
              " 'earlier': 143,\n",
              " 'comes': 144,\n",
              " 'under': 145,\n",
              " 'guarantee': 146,\n",
              " 'dsmp': 147,\n",
              " '2023': 148,\n",
              " 'becomes': 149,\n",
              " 'approx': 150,\n",
              " 'covering': 151,\n",
              " 'following': 152,\n",
              " 'modules': 153,\n",
              " 'fundamentals': 154,\n",
              " 'libraries': 155,\n",
              " 'analysis': 156,\n",
              " 'sql': 157,\n",
              " 'maths': 158,\n",
              " 'machine': 159,\n",
              " 'algorithms': 160,\n",
              " 'practical': 161,\n",
              " 'mlops': 162,\n",
              " 'check': 163,\n",
              " 'detailed': 164,\n",
              " 'courses': 165,\n",
              " '637339afe4b0615a1bbed390': 166,\n",
              " 'both': 167,\n",
              " 'program’s': 168,\n",
              " 'curriculum': 169,\n",
              " 'recorded': 170,\n",
              " 'go': 171,\n",
              " 'back': 172,\n",
              " 'find': 173,\n",
              " 'schedule': 174,\n",
              " 'checkout': 175,\n",
              " 'sheet': 176,\n",
              " 'table': 177,\n",
              " 'docs': 178,\n",
              " 'spreadsheets': 179,\n",
              " 'd': 180,\n",
              " '16ootax': 181,\n",
              " 'a6oraecg4emgexhqqpv3noqpyku7rj6arozk': 182,\n",
              " 'edit': 183,\n",
              " 'usp': 184,\n",
              " 'sharing': 185,\n",
              " 'roughly': 186,\n",
              " 'last': 187,\n",
              " 'hours': 188,\n",
              " 'language': 189,\n",
              " 'spoken': 190,\n",
              " 'instructor': 191,\n",
              " 'during': 192,\n",
              " 'hinglish': 193,\n",
              " 'informed': 194,\n",
              " 'upcoming': 195,\n",
              " 'side': 196,\n",
              " 'before': 197,\n",
              " 'every': 198,\n",
              " 'become': 199,\n",
              " 'user': 200,\n",
              " 'non': 201,\n",
              " 'tech': 202,\n",
              " 'background': 203,\n",
              " 'lectures': 204,\n",
              " 'content': 205,\n",
              " 'provide': 206,\n",
              " 'solutions': 207,\n",
              " 'self': 208,\n",
              " 'evaluate': 209,\n",
              " 'yourself': 210,\n",
              " 'questions': 211,\n",
              " 'youtube': 212,\n",
              " 'channel': 213,\n",
              " 'amount': 214,\n",
              " 'unfortunately': 215,\n",
              " 'then': 216,\n",
              " '1st': 217,\n",
              " '30': 218,\n",
              " 'essentially': 219,\n",
              " 'wait': 220,\n",
              " 'end': 221,\n",
              " 'like': 222,\n",
              " 'making': 223,\n",
              " 'policy': 224,\n",
              " 'made': 225,\n",
              " 'post': 226,\n",
              " 'when': 227,\n",
              " 'view': 228,\n",
              " 'one': 229,\n",
              " 'tricky': 230,\n",
              " 'carefully': 231,\n",
              " 'valid': 232,\n",
              " 'purchased': 233,\n",
              " '20th': 234,\n",
              " 'purchase': 235,\n",
              " 'over': 236,\n",
              " 'installments': 237,\n",
              " 'aug': 238,\n",
              " '2024': 239,\n",
              " 'why': 240,\n",
              " 'lifetime': 241,\n",
              " 'because': 242,\n",
              " 'low': 243,\n",
              " 'reach': 244,\n",
              " 'out': 245,\n",
              " 'fill': 246,\n",
              " 'team': 247,\n",
              " 'still': 248,\n",
              " 'ask': 249,\n",
              " 'doubts': 250,\n",
              " 'select': 251,\n",
              " 'gmai': 252,\n",
              " 'criteria': 253,\n",
              " 'there': 254,\n",
              " 'criterias': 255,\n",
              " 'attempt': 256,\n",
              " 'assessments': 257,\n",
              " 'joining': 258,\n",
              " 'current': 259,\n",
              " 'clarify': 260,\n",
              " 'does': 261,\n",
              " 'mean': 262,\n",
              " 'dont': 263,\n",
              " 'any': 264,\n",
              " 'jobs': 265,\n",
              " 'matter': 266,\n",
              " 'interview': 267,\n",
              " 'calls': 268,\n",
              " 'planning': 269,\n",
              " 'placements': 270,\n",
              " 'afraid': 271,\n",
              " 'disappointed': 272,\n",
              " 'portfolio': 273,\n",
              " 'building': 274,\n",
              " 'soft': 275,\n",
              " 'skill': 276,\n",
              " 'industry': 277,\n",
              " 'mentors': 278,\n",
              " 'discussion': 279,\n",
              " 'job': 280,\n",
              " 'hunting': 281,\n",
              " 'strategies': 282}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woTEmR83iOaY",
        "outputId": "11135b4e-d9e4-4e26-abc5-42c1c244422e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('about', 2),\n",
              "             ('the', 69),\n",
              "             ('program', 11),\n",
              "             ('what', 14),\n",
              "             ('is', 18),\n",
              "             ('course', 12),\n",
              "             ('fee', 5),\n",
              "             ('for', 10),\n",
              "             ('data', 5),\n",
              "             ('science', 4),\n",
              "             ('mentorship', 3),\n",
              "             ('dsmp', 1),\n",
              "             ('2023', 1),\n",
              "             ('follows', 2),\n",
              "             ('a', 19),\n",
              "             ('monthly', 5),\n",
              "             ('subscription', 6),\n",
              "             ('model', 2),\n",
              "             ('where', 6),\n",
              "             ('you', 37),\n",
              "             ('have', 18),\n",
              "             ('to', 27),\n",
              "             ('make', 7),\n",
              "             ('payments', 3),\n",
              "             ('of', 19),\n",
              "             ('rs', 6),\n",
              "             ('799', 3),\n",
              "             ('month', 5),\n",
              "             ('total', 3),\n",
              "             ('duration', 3),\n",
              "             ('7', 4),\n",
              "             ('months', 3),\n",
              "             ('so', 6),\n",
              "             ('becomes', 1),\n",
              "             ('5600', 4),\n",
              "             ('approx', 1),\n",
              "             ('syllabus', 2),\n",
              "             ('we', 7),\n",
              "             ('will', 16),\n",
              "             ('be', 8),\n",
              "             ('covering', 1),\n",
              "             ('following', 1),\n",
              "             ('modules', 1),\n",
              "             ('python', 2),\n",
              "             ('fundamentals', 1),\n",
              "             ('libraries', 1),\n",
              "             ('analysis', 1),\n",
              "             ('sql', 1),\n",
              "             ('maths', 1),\n",
              "             ('machine', 1),\n",
              "             ('learning', 3),\n",
              "             ('ml', 2),\n",
              "             ('algorithms', 1),\n",
              "             ('practical', 1),\n",
              "             ('mlops', 1),\n",
              "             ('case', 3),\n",
              "             ('studies', 2),\n",
              "             ('can', 15),\n",
              "             ('check', 1),\n",
              "             ('detailed', 1),\n",
              "             ('here', 3),\n",
              "             ('https', 3),\n",
              "             ('learnwith', 2),\n",
              "             ('campusx', 6),\n",
              "             ('in', 11),\n",
              "             ('courses', 1),\n",
              "             ('637339afe4b0615a1bbed390', 1),\n",
              "             ('deep', 2),\n",
              "             ('and', 8),\n",
              "             ('nlp', 2),\n",
              "             ('part', 3),\n",
              "             ('this', 8),\n",
              "             ('no', 2),\n",
              "             ('both', 1),\n",
              "             ('are', 4),\n",
              "             ('not', 5),\n",
              "             ('program’s', 1),\n",
              "             ('curriculum', 1),\n",
              "             ('if', 8),\n",
              "             ('i', 28),\n",
              "             ('miss', 2),\n",
              "             ('live', 2),\n",
              "             ('session', 6),\n",
              "             ('get', 5),\n",
              "             ('recording', 2),\n",
              "             ('yes', 5),\n",
              "             ('all', 9),\n",
              "             ('our', 6),\n",
              "             ('sessions', 9),\n",
              "             ('recorded', 1),\n",
              "             ('even', 2),\n",
              "             ('go', 1),\n",
              "             ('back', 1),\n",
              "             ('watch', 4),\n",
              "             ('find', 1),\n",
              "             ('class', 2),\n",
              "             ('schedule', 1),\n",
              "             ('checkout', 1),\n",
              "             ('google', 4),\n",
              "             ('sheet', 1),\n",
              "             ('see', 3),\n",
              "             ('by', 4),\n",
              "             ('time', 2),\n",
              "             ('table', 1),\n",
              "             ('docs', 1),\n",
              "             ('com', 4),\n",
              "             ('spreadsheets', 1),\n",
              "             ('d', 1),\n",
              "             ('16ootax', 1),\n",
              "             ('a6oraecg4emgexhqqpv3noqpyku7rj6arozk', 1),\n",
              "             ('edit', 1),\n",
              "             ('usp', 1),\n",
              "             ('sharing', 1),\n",
              "             ('roughly', 1),\n",
              "             ('last', 1),\n",
              "             ('2', 2),\n",
              "             ('hours', 1),\n",
              "             ('language', 1),\n",
              "             ('spoken', 1),\n",
              "             ('instructor', 1),\n",
              "             ('during', 1),\n",
              "             ('hinglish', 1),\n",
              "             ('how', 2),\n",
              "             ('informed', 1),\n",
              "             ('upcoming', 1),\n",
              "             ('mail', 4),\n",
              "             ('from', 4),\n",
              "             ('side', 1),\n",
              "             ('before', 1),\n",
              "             ('every', 1),\n",
              "             ('paid', 6),\n",
              "             ('once', 5),\n",
              "             ('become', 1),\n",
              "             ('user', 1),\n",
              "             ('do', 7),\n",
              "             ('am', 8),\n",
              "             ('non', 1),\n",
              "             ('tech', 1),\n",
              "             ('background', 1),\n",
              "             ('absolutely', 2),\n",
              "             ('late', 3),\n",
              "             ('join', 6),\n",
              "             ('middle', 2),\n",
              "             ('anytime', 2),\n",
              "             ('pay', 8),\n",
              "             ('able', 6),\n",
              "             ('past', 5),\n",
              "             ('lectures', 1),\n",
              "             ('payment', 8),\n",
              "             ('content', 1),\n",
              "             ('your', 6),\n",
              "             ('dashboard', 3),\n",
              "             ('submit', 2),\n",
              "             ('task', 3),\n",
              "             ('don’t', 3),\n",
              "             ('provide', 1),\n",
              "             ('with', 2),\n",
              "             ('solutions', 1),\n",
              "             ('self', 1),\n",
              "             ('evaluate', 1),\n",
              "             ('yourself', 1),\n",
              "             ('contact', 4),\n",
              "             ('us', 4),\n",
              "             ('at', 4),\n",
              "             ('nitish', 3),\n",
              "             ('gmail', 2),\n",
              "             ('registration', 2),\n",
              "             ('related', 2),\n",
              "             ('questions', 1),\n",
              "             ('youtube', 1),\n",
              "             ('channel', 1),\n",
              "             ('or', 4),\n",
              "             ('website', 6),\n",
              "             ('on', 9),\n",
              "             ('link', 2),\n",
              "             ('entire', 2),\n",
              "             ('amount', 1),\n",
              "             ('unfortunately', 1),\n",
              "             ('validity', 3),\n",
              "             ('suppose', 2),\n",
              "             ('15th', 3),\n",
              "             ('jan', 3),\n",
              "             ('then', 1),\n",
              "             ('again', 2),\n",
              "             ('1st', 1),\n",
              "             ('feb', 5),\n",
              "             ('period', 3),\n",
              "             ('30', 1),\n",
              "             ('days', 2),\n",
              "             ('day', 2),\n",
              "             ('essentially', 1),\n",
              "             ('wait', 1),\n",
              "             ('end', 1),\n",
              "             ('like', 1),\n",
              "             ('after', 3),\n",
              "             ('making', 1),\n",
              "             ('refund', 2),\n",
              "             ('policy', 1),\n",
              "             ('made', 1),\n",
              "             ('living', 2),\n",
              "             ('outside', 2),\n",
              "             ('india', 2),\n",
              "             ('should', 2),\n",
              "             ('sending', 2),\n",
              "             ('post', 1),\n",
              "             ('queries', 2),\n",
              "             ('till', 3),\n",
              "             ('when', 1),\n",
              "             ('view', 1),\n",
              "             ('videos', 2),\n",
              "             ('one', 1),\n",
              "             ('tricky', 1),\n",
              "             ('read', 2),\n",
              "             ('carefully', 1),\n",
              "             ('valid', 1),\n",
              "             ('purchased', 1),\n",
              "             ('21st', 3),\n",
              "             ('20th', 1),\n",
              "             ('but', 2),\n",
              "             ('purchase', 1),\n",
              "             ('over', 1),\n",
              "             ('installments', 1),\n",
              "             ('aug', 1),\n",
              "             ('2024', 1),\n",
              "             ('why', 1),\n",
              "             ('lifetime', 1),\n",
              "             ('provided', 2),\n",
              "             ('because', 1),\n",
              "             ('low', 1),\n",
              "             ('reach', 1),\n",
              "             ('out', 1),\n",
              "             ('doubt', 4),\n",
              "             ('fill', 1),\n",
              "             ('form', 2),\n",
              "             ('team', 1),\n",
              "             ('1', 2),\n",
              "             ('clearance', 2),\n",
              "             ('still', 1),\n",
              "             ('ask', 1),\n",
              "             ('week', 2),\n",
              "             ('doubts', 1),\n",
              "             ('just', 2),\n",
              "             ('select', 1),\n",
              "             ('gmai', 1),\n",
              "             ('certificate', 2),\n",
              "             ('placement', 6),\n",
              "             ('assistance', 5),\n",
              "             ('criteria', 1),\n",
              "             ('there', 1),\n",
              "             ('criterias', 1),\n",
              "             ('attempt', 1),\n",
              "             ('assessments', 1),\n",
              "             ('joining', 1),\n",
              "             ('earlier', 2),\n",
              "             ('current', 1),\n",
              "             ('that', 3),\n",
              "             ('comes', 2),\n",
              "             ('under', 2),\n",
              "             ('clarify', 1),\n",
              "             ('does', 1),\n",
              "             ('mean', 1),\n",
              "             ('guarantee', 2),\n",
              "             ('dont', 1),\n",
              "             ('any', 1),\n",
              "             ('jobs', 1),\n",
              "             ('matter', 1),\n",
              "             ('interview', 1),\n",
              "             ('calls', 1),\n",
              "             ('planning', 1),\n",
              "             ('placements', 1),\n",
              "             ('afraid', 1),\n",
              "             ('disappointed', 1),\n",
              "             ('portfolio', 1),\n",
              "             ('building', 1),\n",
              "             ('soft', 1),\n",
              "             ('skill', 1),\n",
              "             ('industry', 1),\n",
              "             ('mentors', 1),\n",
              "             ('discussion', 1),\n",
              "             ('job', 1),\n",
              "             ('hunting', 1),\n",
              "             ('strategies', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentence in faqs.split('\\n'):\n",
        "  print(sentence)\n",
        "  print(tokenizer.texts_to_sequences([sentence]))\n",
        "  #for every sentence it creates an array\n",
        "  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "u5U8WkIHiXnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47df8c94-d804-4548-c861-5fa4241fa487"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "About the Program\n",
            "[[93, 1, 13]]\n",
            "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
            "[[11, 7, 1, 12, 42, 15, 43, 53, 68, 13, 147, 148]]\n",
            "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
            "[[1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31, 70, 45]]\n",
            "What is the total duration of the course?\n",
            "[[11, 7, 1, 71, 72, 6, 1, 12]]\n",
            "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
            "[[1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31, 55, 150]]\n",
            "What is the syllabus of the mentorship program?\n",
            "[[11, 7, 1, 96, 6, 1, 68, 13]]\n",
            "We will be covering the following modules:\n",
            "[[27, 9, 19, 151, 1, 152, 153]]\n",
            "Python Fundamentals\n",
            "[[97, 154]]\n",
            "Python libraries for Data Science\n",
            "[[97, 155, 15, 43, 53]]\n",
            "Data Analysis\n",
            "[[43, 156]]\n",
            "SQL for Data Science\n",
            "[[157, 15, 43, 53]]\n",
            "Maths for Machine Learning\n",
            "[[158, 15, 159, 74]]\n",
            "ML Algorithms\n",
            "[[98, 160]]\n",
            "Practical ML\n",
            "[[161, 98]]\n",
            "MLOPs\n",
            "[[162]]\n",
            "Case studies\n",
            "[[75, 99]]\n",
            "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
            "[[2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68, 13, 166]]\n",
            "Will Deep Learning and NLP be a part of this program?\n",
            "[[9, 101, 74, 20, 102, 19, 5, 78, 6, 21, 13]]\n",
            "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
            "[[103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21, 168, 169]]\n",
            "What if I miss a live session? Will I get a recording of the session?\n",
            "[[11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6, 1, 34]]\n",
            "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
            "[[48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57, 1, 106]]\n",
            "Where can I find the class schedule?\n",
            "[[30, 10, 3, 173, 1, 108, 174]]\n",
            "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
            "[[175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183, 184, 185]]\n",
            "What is the time duration of all the live sessions?\n",
            "[[11, 7, 1, 109, 72, 6, 16, 1, 105, 17]]\n",
            "Roughly, all the sessions last 2 hours.\n",
            "[[186, 16, 1, 17, 187, 110, 188]]\n",
            "What is the language spoken by the instructor during the sessions?\n",
            "[[11, 7, 1, 189, 190, 59, 1, 191, 192, 1, 17]]\n",
            "Hinglish\n",
            "[[193]]\n",
            "How will I be informed about the upcoming class?\n",
            "[[111, 9, 3, 19, 194, 93, 1, 195, 108]]\n",
            "You will get a mail from our side before every paid session once you become a paid user.\n",
            "[[2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5, 36, 200]]\n",
            "Can I do this course if I am from a non-tech background?\n",
            "[[10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201, 202, 203]]\n",
            "Yes, absolutely.\n",
            "[[48, 112]]\n",
            "I am late, can I join the program in the middle?\n",
            "[[3, 23, 80, 10, 3, 37, 1, 13, 14, 1, 113]]\n",
            "Absolutely, you can join the program anytime.\n",
            "[[112, 2, 10, 37, 1, 13, 114]]\n",
            "If I join/pay in the middle, will I be able to see all the past lectures?\n",
            "[[22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1, 50, 204]]\n",
            "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
            "[[48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14, 39, 81]]\n",
            "Where do I have to submit the task?\n",
            "[[30, 28, 3, 8, 4, 115, 1, 82]]\n",
            "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
            "[[2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1, 82, 210]]\n",
            "Will we do case studies in the program?\n",
            "[[9, 27, 28, 75, 99, 14, 1, 13]]\n",
            "Yes.\n",
            "[[48]]\n",
            "Where can we contact you?\n",
            "[[30, 10, 27, 63, 2]]\n",
            "You can mail us at nitish.campusx@gmail.com\n",
            "[[2, 10, 61, 64, 65, 84, 33, 117, 60]]\n",
            "Payment/Registration related questions\n",
            "[[25, 118, 119, 211]]\n",
            "Where do we have to make our payments? Your YouTube channel or website?\n",
            "[[30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213, 66, 40]]\n",
            "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
            "[[2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100, 33, 14]]\n",
            "Can we pay the entire amount of Rs 5600 all at once?\n",
            "[[10, 27, 24, 1, 121, 214, 6, 31, 55, 16, 65, 49]]\n",
            "Unfortunately no, the program follows a monthly subscription model.\n",
            "[[215, 103, 1, 13, 94, 5, 44, 29, 95]]\n",
            "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
            "[[11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66, 86, 51]]\n",
            "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
            "[[86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45, 4, 221]]\n",
            "What if I don’t like the course after making the payment. What is the refund policy?\n",
            "[[11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1, 126, 224]]\n",
            "You get a 7 days refund period from the day you have made the payment.\n",
            "[[2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225, 1, 25]]\n",
            "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
            "[[3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28]]\n",
            "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
            "[[2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 117, 60]]\n",
            "Post registration queries\n",
            "[[226, 118, 132]]\n",
            "Till when can I view the paid videos on the website?\n",
            "[[90, 227, 10, 3, 228, 1, 36, 133, 18, 1, 40]]\n",
            "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
            "[[21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1, 29, 123]]\n",
            "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
            "[[135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90, 238, 239]]\n",
            "Why lifetime validity is not provided?\n",
            "[[240, 241, 85, 7, 46, 136]]\n",
            "Because of the low course fee.\n",
            "[[242, 6, 1, 243, 12, 42]]\n",
            "Where can I reach out in case of a doubt after the session?\n",
            "[[30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89, 1, 34]]\n",
            "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
            "[[2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67, 139, 34]]\n",
            "If I join the program late, can I still ask past week doubts?\n",
            "[[22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50, 140, 250]]\n",
            "Yes, just select past week doubt in the doubt clearance google form.\n",
            "[[48, 141, 251, 50, 140, 67, 14, 1, 67, 139, 58, 137]]\n",
            "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
            "[[3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28]]\n",
            "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
            "[[2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 252, 60]]\n",
            "Certificate and Placement Assistance related queries\n",
            "[[142, 20, 41, 52, 119, 132]]\n",
            "What is the criteria to get the certificate?\n",
            "[[11, 7, 1, 253, 4, 47, 1, 142]]\n",
            "There are 2 criterias:\n",
            "[[254, 56, 110, 255]]\n",
            "You have to pay the entire fee of Rs 5600\n",
            "[[2, 8, 4, 24, 1, 121, 42, 6, 31, 55]]\n",
            "You have to attempt all the course assessments.\n",
            "[[2, 8, 4, 256, 16, 1, 12, 257]]\n",
            "I am joining late. How can I pay payment of the earlier months?\n",
            "[[3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1, 143, 73]]\n",
            "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
            "[[2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1, 259, 45]]\n",
            "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
            "[[3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145, 41, 52]]\n",
            "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
            "[[21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145, 41, 52]]\n",
            "Portfolio Building sessions\n",
            "[[273, 274, 17]]\n",
            "Soft skill sessions\n",
            "[[275, 276, 17]]\n",
            "Sessions with industry mentors\n",
            "[[17, 116, 277, 278]]\n",
            "Discussion on Job hunting strategies\n",
            "[[279, 18, 280, 281, 282]]\n",
            "\n",
            "[[]]\n",
            "[[93, 1], [93, 1, 13], [11, 7], [11, 7, 1], [11, 7, 1, 12], [11, 7, 1, 12, 42], [11, 7, 1, 12, 42, 15], [11, 7, 1, 12, 42, 15, 43], [11, 7, 1, 12, 42, 15, 43, 53], [11, 7, 1, 12, 42, 15, 43, 53, 68], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13, 147], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13, 147, 148], [1, 12], [1, 12, 94], [1, 12, 94, 5], [1, 12, 94, 5, 44], [1, 12, 94, 5, 44, 29], [1, 12, 94, 5, 44, 29, 95], [1, 12, 94, 5, 44, 29, 95, 30], [1, 12, 94, 5, 44, 29, 95, 30, 2], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31, 70], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31, 70, 45], [11, 7], [11, 7, 1], [11, 7, 1, 71], [11, 7, 1, 71, 72], [11, 7, 1, 71, 72, 6], [11, 7, 1, 71, 72, 6, 1], [11, 7, 1, 71, 72, 6, 1, 12], [1, 71], [1, 71, 72], [1, 71, 72, 6], [1, 71, 72, 6, 1], [1, 71, 72, 6, 1, 12], [1, 71, 72, 6, 1, 12, 7], [1, 71, 72, 6, 1, 12, 7, 54], [1, 71, 72, 6, 1, 12, 7, 54, 73], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31, 55], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31, 55, 150], [11, 7], [11, 7, 1], [11, 7, 1, 96], [11, 7, 1, 96, 6], [11, 7, 1, 96, 6, 1], [11, 7, 1, 96, 6, 1, 68], [11, 7, 1, 96, 6, 1, 68, 13], [27, 9], [27, 9, 19], [27, 9, 19, 151], [27, 9, 19, 151, 1], [27, 9, 19, 151, 1, 152], [27, 9, 19, 151, 1, 152, 153], [97, 154], [97, 155], [97, 155, 15], [97, 155, 15, 43], [97, 155, 15, 43, 53], [43, 156], [157, 15], [157, 15, 43], [157, 15, 43, 53], [158, 15], [158, 15, 159], [158, 15, 159, 74], [98, 160], [161, 98], [75, 99], [2, 10], [2, 10, 163], [2, 10, 163, 1], [2, 10, 163, 1, 164], [2, 10, 163, 1, 164, 96], [2, 10, 163, 1, 164, 96, 76], [2, 10, 163, 1, 164, 96, 76, 77], [2, 10, 163, 1, 164, 96, 76, 77, 100], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68, 13], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68, 13, 166], [9, 101], [9, 101, 74], [9, 101, 74, 20], [9, 101, 74, 20, 102], [9, 101, 74, 20, 102, 19], [9, 101, 74, 20, 102, 19, 5], [9, 101, 74, 20, 102, 19, 5, 78], [9, 101, 74, 20, 102, 19, 5, 78, 6], [9, 101, 74, 20, 102, 19, 5, 78, 6, 21], [9, 101, 74, 20, 102, 19, 5, 78, 6, 21, 13], [103, 102], [103, 102, 20], [103, 102, 20, 101], [103, 102, 20, 101, 74], [103, 102, 20, 101, 74, 167], [103, 102, 20, 101, 74, 167, 56], [103, 102, 20, 101, 74, 167, 56, 46], [103, 102, 20, 101, 74, 167, 56, 46, 5], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21, 168], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21, 168, 169], [11, 22], [11, 22, 3], [11, 22, 3, 104], [11, 22, 3, 104, 5], [11, 22, 3, 104, 5, 105], [11, 22, 3, 104, 5, 105, 34], [11, 22, 3, 104, 5, 105, 34, 9], [11, 22, 3, 104, 5, 105, 34, 9, 3], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6, 1], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6, 1, 34], [48, 16], [48, 16, 35], [48, 16, 35, 17], [48, 16, 35, 17, 56], [48, 16, 35, 17, 56, 170], [48, 16, 35, 17, 56, 170, 32], [48, 16, 35, 17, 56, 170, 32, 107], [48, 16, 35, 17, 56, 170, 32, 107, 22], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57, 1], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57, 1, 106], [30, 10], [30, 10, 3], [30, 10, 3, 173], [30, 10, 3, 173, 1], [30, 10, 3, 173, 1, 108], [30, 10, 3, 173, 1, 108, 174], [175, 21], [175, 21, 58], [175, 21, 58, 176], [175, 21, 58, 176, 4], [175, 21, 58, 176, 4, 79], [175, 21, 58, 176, 4, 79, 45], [175, 21, 58, 176, 4, 79, 45, 59], [175, 21, 58, 176, 4, 79, 45, 59, 45], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183, 184], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183, 184, 185], [11, 7], [11, 7, 1], [11, 7, 1, 109], [11, 7, 1, 109, 72], [11, 7, 1, 109, 72, 6], [11, 7, 1, 109, 72, 6, 16], [11, 7, 1, 109, 72, 6, 16, 1], [11, 7, 1, 109, 72, 6, 16, 1, 105], [11, 7, 1, 109, 72, 6, 16, 1, 105, 17], [186, 16], [186, 16, 1], [186, 16, 1, 17], [186, 16, 1, 17, 187], [186, 16, 1, 17, 187, 110], [186, 16, 1, 17, 187, 110, 188], [11, 7], [11, 7, 1], [11, 7, 1, 189], [11, 7, 1, 189, 190], [11, 7, 1, 189, 190, 59], [11, 7, 1, 189, 190, 59, 1], [11, 7, 1, 189, 190, 59, 1, 191], [11, 7, 1, 189, 190, 59, 1, 191, 192], [11, 7, 1, 189, 190, 59, 1, 191, 192, 1], [11, 7, 1, 189, 190, 59, 1, 191, 192, 1, 17], [111, 9], [111, 9, 3], [111, 9, 3, 19], [111, 9, 3, 19, 194], [111, 9, 3, 19, 194, 93], [111, 9, 3, 19, 194, 93, 1], [111, 9, 3, 19, 194, 93, 1, 195], [111, 9, 3, 19, 194, 93, 1, 195, 108], [2, 9], [2, 9, 47], [2, 9, 47, 5], [2, 9, 47, 5, 61], [2, 9, 47, 5, 61, 62], [2, 9, 47, 5, 61, 62, 35], [2, 9, 47, 5, 61, 62, 35, 196], [2, 9, 47, 5, 61, 62, 35, 196, 197], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5, 36], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5, 36, 200], [10, 3], [10, 3, 28], [10, 3, 28, 21], [10, 3, 28, 21, 12], [10, 3, 28, 21, 12, 22], [10, 3, 28, 21, 12, 22, 3], [10, 3, 28, 21, 12, 22, 3, 23], [10, 3, 28, 21, 12, 22, 3, 23, 62], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201, 202], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201, 202, 203], [48, 112], [3, 23], [3, 23, 80], [3, 23, 80, 10], [3, 23, 80, 10, 3], [3, 23, 80, 10, 3, 37], [3, 23, 80, 10, 3, 37, 1], [3, 23, 80, 10, 3, 37, 1, 13], [3, 23, 80, 10, 3, 37, 1, 13, 14], [3, 23, 80, 10, 3, 37, 1, 13, 14, 1], [3, 23, 80, 10, 3, 37, 1, 13, 14, 1, 113], [112, 2], [112, 2, 10], [112, 2, 10, 37], [112, 2, 10, 37, 1], [112, 2, 10, 37, 1, 13], [112, 2, 10, 37, 1, 13, 114], [22, 3], [22, 3, 37], [22, 3, 37, 24], [22, 3, 37, 24, 14], [22, 3, 37, 24, 14, 1], [22, 3, 37, 24, 14, 1, 113], [22, 3, 37, 24, 14, 1, 113, 9], [22, 3, 37, 24, 14, 1, 113, 9, 3], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1, 50], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1, 50, 204], [48, 49], [48, 49, 2], [48, 49, 2, 26], [48, 49, 2, 26, 1], [48, 49, 2, 26, 1, 25], [48, 49, 2, 26, 1, 25, 2], [48, 49, 2, 26, 1, 25, 2, 9], [48, 49, 2, 26, 1, 25, 2, 9, 19], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14, 39], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14, 39, 81], [30, 28], [30, 28, 3], [30, 28, 3, 8], [30, 28, 3, 8, 4], [30, 28, 3, 8, 4, 115], [30, 28, 3, 8, 4, 115, 1], [30, 28, 3, 8, 4, 115, 1, 82], [2, 83], [2, 83, 8], [2, 83, 8, 4], [2, 83, 8, 4, 115], [2, 83, 8, 4, 115, 1], [2, 83, 8, 4, 115, 1, 82], [2, 83, 8, 4, 115, 1, 82, 27], [2, 83, 8, 4, 115, 1, 82, 27, 9], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1, 82], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1, 82, 210], [9, 27], [9, 27, 28], [9, 27, 28, 75], [9, 27, 28, 75, 99], [9, 27, 28, 75, 99, 14], [9, 27, 28, 75, 99, 14, 1], [9, 27, 28, 75, 99, 14, 1, 13], [30, 10], [30, 10, 27], [30, 10, 27, 63], [30, 10, 27, 63, 2], [2, 10], [2, 10, 61], [2, 10, 61, 64], [2, 10, 61, 64, 65], [2, 10, 61, 64, 65, 84], [2, 10, 61, 64, 65, 84, 33], [2, 10, 61, 64, 65, 84, 33, 117], [2, 10, 61, 64, 65, 84, 33, 117, 60], [25, 118], [25, 118, 119], [25, 118, 119, 211], [30, 28], [30, 28, 27], [30, 28, 27, 8], [30, 28, 27, 8, 4], [30, 28, 27, 8, 4, 26], [30, 28, 27, 8, 4, 26, 35], [30, 28, 27, 8, 4, 26, 35, 69], [30, 28, 27, 8, 4, 26, 35, 69, 39], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213, 66], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213, 66, 40], [2, 8], [2, 8, 4], [2, 8, 4, 26], [2, 8, 4, 26, 16], [2, 8, 4, 26, 16, 39], [2, 8, 4, 26, 16, 39, 44], [2, 8, 4, 26, 16, 39, 44, 69], [2, 8, 4, 26, 16, 39, 44, 69, 18], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100, 33], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100, 33, 14], [10, 27], [10, 27, 24], [10, 27, 24, 1], [10, 27, 24, 1, 121], [10, 27, 24, 1, 121, 214], [10, 27, 24, 1, 121, 214, 6], [10, 27, 24, 1, 121, 214, 6, 31], [10, 27, 24, 1, 121, 214, 6, 31, 55], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16, 65], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16, 65, 49], [215, 103], [215, 103, 1], [215, 103, 1, 13], [215, 103, 1, 13, 94], [215, 103, 1, 13, 94, 5], [215, 103, 1, 13, 94, 5, 44], [215, 103, 1, 13, 94, 5, 44, 29], [215, 103, 1, 13, 94, 5, 44, 29, 95], [11, 7], [11, 7, 1], [11, 7, 1, 85], [11, 7, 1, 85, 6], [11, 7, 1, 85, 6, 44], [11, 7, 1, 85, 6, 44, 29], [11, 7, 1, 85, 6, 44, 29, 122], [11, 7, 1, 85, 6, 44, 29, 122, 22], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66, 86], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66, 86, 51], [86, 51], [86, 51, 1], [86, 51, 1, 85], [86, 51, 1, 85, 88], [86, 51, 1, 85, 88, 7], [86, 51, 1, 85, 88, 7, 218], [86, 51, 1, 85, 88, 7, 218, 124], [86, 51, 1, 85, 88, 7, 218, 124, 62], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45, 4], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45, 4, 221], [11, 22], [11, 22, 3], [11, 22, 3, 83], [11, 22, 3, 83, 222], [11, 22, 3, 83, 222, 1], [11, 22, 3, 83, 222, 1, 12], [11, 22, 3, 83, 222, 1, 12, 89], [11, 22, 3, 83, 222, 1, 12, 89, 223], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1, 126], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1, 126, 224], [2, 47], [2, 47, 5], [2, 47, 5, 54], [2, 47, 5, 54, 124], [2, 47, 5, 54, 124, 126], [2, 47, 5, 54, 124, 126, 88], [2, 47, 5, 54, 124, 126, 88, 62], [2, 47, 5, 54, 124, 126, 88, 62, 1], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225, 1], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225, 1, 25], [3, 23], [3, 23, 127], [3, 23, 127, 128], [3, 23, 127, 128, 129], [3, 23, 127, 128, 129, 20], [3, 23, 127, 128, 129, 20, 3], [3, 23, 127, 128, 129, 20, 3, 23], [3, 23, 127, 128, 129, 20, 3, 23, 46], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28], [2, 8], [2, 8, 4], [2, 8, 4, 63], [2, 8, 4, 63, 64], [2, 8, 4, 63, 64, 59], [2, 8, 4, 63, 64, 59, 131], [2, 8, 4, 63, 64, 59, 131, 5], [2, 8, 4, 63, 64, 59, 131, 5, 61], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 117], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 117, 60], [226, 118], [226, 118, 132], [90, 227], [90, 227, 10], [90, 227, 10, 3], [90, 227, 10, 3, 228], [90, 227, 10, 3, 228, 1], [90, 227, 10, 3, 228, 1, 36], [90, 227, 10, 3, 228, 1, 36, 133], [90, 227, 10, 3, 228, 1, 36, 133, 18], [90, 227, 10, 3, 228, 1, 36, 133, 18, 1], [90, 227, 10, 3, 228, 1, 36, 133, 18, 1, 40], [21, 229], [21, 229, 7], [21, 229, 7, 230], [21, 229, 7, 230, 32], [21, 229, 7, 230, 32, 134], [21, 229, 7, 230, 32, 134, 231], [21, 229, 7, 230, 32, 134, 231, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1, 29, 123], [135, 49], [135, 49, 1], [135, 49, 1, 12], [135, 49, 1, 12, 7], [135, 49, 1, 12, 7, 236], [135, 49, 1, 12, 7, 236, 20], [135, 49, 1, 12, 7, 236, 20, 2], [135, 49, 1, 12, 7, 236, 20, 2, 8], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90, 238], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90, 238, 239], [240, 241], [240, 241, 85], [240, 241, 85, 7], [240, 241, 85, 7, 46], [240, 241, 85, 7, 46, 136], [242, 6], [242, 6, 1], [242, 6, 1, 243], [242, 6, 1, 243, 12], [242, 6, 1, 243, 12, 42], [30, 10], [30, 10, 3], [30, 10, 3, 244], [30, 10, 3, 244, 245], [30, 10, 3, 244, 245, 14], [30, 10, 3, 244, 245, 14, 75], [30, 10, 3, 244, 245, 14, 75, 6], [30, 10, 3, 244, 245, 14, 75, 6, 5], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89, 1], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89, 1, 34], [2, 9], [2, 9, 8], [2, 9, 8, 4], [2, 9, 8, 4, 246], [2, 9, 8, 4, 246, 5], [2, 9, 8, 4, 246, 5, 58], [2, 9, 8, 4, 246, 5, 58, 137], [2, 9, 8, 4, 246, 5, 58, 137, 136], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67, 139], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67, 139, 34], [22, 3], [22, 3, 37], [22, 3, 37, 1], [22, 3, 37, 1, 13], [22, 3, 37, 1, 13, 80], [22, 3, 37, 1, 13, 80, 10], [22, 3, 37, 1, 13, 80, 10, 3], [22, 3, 37, 1, 13, 80, 10, 3, 248], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50, 140], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50, 140, 250], [48, 141], [48, 141, 251], [48, 141, 251, 50], [48, 141, 251, 50, 140], [48, 141, 251, 50, 140, 67], [48, 141, 251, 50, 140, 67, 14], [48, 141, 251, 50, 140, 67, 14, 1], [48, 141, 251, 50, 140, 67, 14, 1, 67], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139, 58], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139, 58, 137], [3, 23], [3, 23, 127], [3, 23, 127, 128], [3, 23, 127, 128, 129], [3, 23, 127, 128, 129, 20], [3, 23, 127, 128, 129, 20, 3], [3, 23, 127, 128, 129, 20, 3, 23], [3, 23, 127, 128, 129, 20, 3, 23, 46], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28], [2, 8], [2, 8, 4], [2, 8, 4, 63], [2, 8, 4, 63, 64], [2, 8, 4, 63, 64, 59], [2, 8, 4, 63, 64, 59, 131], [2, 8, 4, 63, 64, 59, 131, 5], [2, 8, 4, 63, 64, 59, 131, 5, 61], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 252], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 252, 60], [142, 20], [142, 20, 41], [142, 20, 41, 52], [142, 20, 41, 52, 119], [142, 20, 41, 52, 119, 132], [11, 7], [11, 7, 1], [11, 7, 1, 253], [11, 7, 1, 253, 4], [11, 7, 1, 253, 4, 47], [11, 7, 1, 253, 4, 47, 1], [11, 7, 1, 253, 4, 47, 1, 142], [254, 56], [254, 56, 110], [254, 56, 110, 255], [2, 8], [2, 8, 4], [2, 8, 4, 24], [2, 8, 4, 24, 1], [2, 8, 4, 24, 1, 121], [2, 8, 4, 24, 1, 121, 42], [2, 8, 4, 24, 1, 121, 42, 6], [2, 8, 4, 24, 1, 121, 42, 6, 31], [2, 8, 4, 24, 1, 121, 42, 6, 31, 55], [2, 8], [2, 8, 4], [2, 8, 4, 256], [2, 8, 4, 256, 16], [2, 8, 4, 256, 16, 1], [2, 8, 4, 256, 16, 1, 12], [2, 8, 4, 256, 16, 1, 12, 257], [3, 23], [3, 23, 258], [3, 23, 258, 80], [3, 23, 258, 80, 111], [3, 23, 258, 80, 111, 10], [3, 23, 258, 80, 111, 10, 3], [3, 23, 258, 80, 111, 10, 3, 24], [3, 23, 258, 80, 111, 10, 3, 24, 25], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1, 143], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1, 143, 73], [2, 9], [2, 9, 47], [2, 9, 47, 5], [2, 9, 47, 5, 120], [2, 9, 47, 5, 120, 4], [2, 9, 47, 5, 120, 4, 24], [2, 9, 47, 5, 120, 4, 24, 42], [2, 9, 47, 5, 120, 4, 24, 42, 6], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1, 259], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1, 259, 45], [3, 8], [3, 8, 134], [3, 8, 134, 92], [3, 8, 134, 92, 41], [3, 8, 134, 92, 41, 52], [3, 8, 134, 92, 41, 52, 7], [3, 8, 134, 92, 41, 52, 7, 5], [3, 8, 134, 92, 41, 52, 7, 5, 78], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145, 41], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145, 41, 52], [21, 7], [21, 7, 4], [21, 7, 4, 260], [21, 7, 4, 260, 92], [21, 7, 4, 260, 92, 41], [21, 7, 4, 260, 92, 41, 52], [21, 7, 4, 260, 92, 41, 52, 261], [21, 7, 4, 260, 92, 41, 52, 261, 46], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145, 41], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145, 41, 52], [273, 274], [273, 274, 17], [275, 276], [275, 276, 17], [17, 116], [17, 116, 277], [17, 116, 277, 278], [279, 18], [279, 18, 280], [279, 18, 280, 281], [279, 18, 280, 281, 282]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byLWOpLKjdHF",
        "outputId": "f024873a-cc84-433d-84e8-d17d9b6d0c03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[93, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "4MhKo7E8krWX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "jhdKyeZPlTlp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "vPR9SXHilUQJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=padded_input_sequences[:,:-1]\n",
        "#taking all values except the last value"
      ],
      "metadata": {
        "id": "OFu8vjDZlgU2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=padded_input_sequences[:,-1]\n",
        "#taking only the last values"
      ],
      "metadata": {
        "id": "a2-g1w1eluuU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_o5DXxt67T",
        "outputId": "dae285e4-0abb-4f22-fe3f-f0b327d7313a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0   0  93]\n",
            " [  0   0   0 ...   0  93   1]\n",
            " [  0   0   0 ...   0   0  11]\n",
            " ...\n",
            " [  0   0   0 ...   0 279  18]\n",
            " [  0   0   0 ... 279  18 280]\n",
            " [  0   0   0 ...  18 280 281]] [  1  13   7   1  12  42  15  43  53  68  13 147 148  12  94   5  44  29\n",
            "  95  30   2   8   4  26  44  69   6  31  70  45   7   1  71  72   6   1\n",
            "  12  71  72   6   1  12   7  54  73  32   1  71  12  42 149  70  54  31\n",
            "  55 150   7   1  96   6   1  68  13   9  19 151   1 152 153 154 155  15\n",
            "  43  53 156  15  43  53  15 159  74 160  98  99  10 163   1 164  96  76\n",
            "  77 100  33  14 165  33  43  53  68  13 166 101  74  20 102  19   5  78\n",
            "   6  21  13 102  20 101  74 167  56  46   5  78   6  21 168 169  22   3\n",
            " 104   5 105  34   9   3  47   5 106   6   1  34  16  35  17  56 170  32\n",
            " 107  22   2 104   5  34   2  10 171 172  20  57   1 106  10   3 173   1\n",
            " 108 174  21  58 176   4  79  45  59  45 109 177   6   1  12  77 178  58\n",
            "  60 179 180 181 182 183 184 185   7   1 109  72   6  16   1 105  17  16\n",
            "   1  17 187 110 188   7   1 189 190  59   1 191 192   1  17   9   3  19\n",
            " 194  93   1 195 108   9  47   5  61  62  35 196 197 198  36  34  49   2\n",
            " 199   5  36 200   3  28  21  12  22   3  23  62   5 201 202 203 112  23\n",
            "  80  10   3  37   1  13  14   1 113   2  10  37   1  13 114   3  37  24\n",
            "  14   1 113   9   3  19  38   4  79  16   1  50 204  49   2  26   1  25\n",
            "   2   9  19  38   4  79  16   1  50 205  14  39  81  28   3   8   4 115\n",
            "   1  82  83   8   4 115   1  82  27   9 206   2 116   1 207   2   8   4\n",
            " 208 209   1  82 210  27  28  75  99  14   1  13  10  27  63   2  10  61\n",
            "  64  65  84  33 117  60 118 119 211  28  27   8   4  26  35  69  39 212\n",
            " 213  66  40   8   4  26  16  39  44  69  18  35  40  76   7   1 120  15\n",
            "  35  40  77 100  33  14  27  24   1 121 214   6  31  55  16  65  49 103\n",
            "   1  13  94   5  44  29  95   7   1  85   6  44  29 122  22   3  24  18\n",
            "  86  87 216  28   3   8   4  24 123  18 217  51  66  86  51  51   1  85\n",
            "  88   7 218 124  62   1 125   2  26   1  25  32 219   2  10  37 114   2\n",
            "  83   8   4 220  15   5  45   4 221  22   3  83 222   1  12  89 223   1\n",
            "  25  11   7   1 126 224  47   5  54 124 126  88  62   1 125   2   8 225\n",
            "   1  25  23 127 128 129  20   3  23  46  38   4  26   1  25  18   1  40\n",
            "  11 130   3  28   8   4  63  64  59 131   5  61  65  84  33 117  60 118\n",
            " 132 227  10   3 228   1  36 133  18   1  40 229   7 230  32 134 231   2\n",
            "  10  57   1 133  90  39  29   7 232 122   2   8 233  29  18  91  87   2\n",
            "   9  19  38   4  57  16   1  50  36  17  14   1  88   6  91  87   4 234\n",
            "  51 135  89  91  51   2   9   8   4 235   1  29 123  49   1  12   7 236\n",
            "  20   2   8  36  64  31  55  66  54 237   6  31  70   2   9  19  38   4\n",
            "  57   1  36  17  90 238 239 241  85   7  46 136   6   1 243  12  42  10\n",
            "   3 244 245  14  75   6   5  67  89   1  34   9   8   4 246   5  58 137\n",
            " 136  14  39  81  20  35 247   9  63   2  15   5 138  18 138  67 139  34\n",
            "   3  37   1  13  80  10   3 248 249  50 140 250 141 251  50 140  67  14\n",
            "   1  67 139  58 137  23 127 128 129  20   3  23  46  38   4  26   1  25\n",
            "  18   1  40  11 130   3  28   8   4  63  64  59 131   5  61  65  84  33\n",
            " 252  60  20  41  52 119 132   7   1 253   4  47   1 142  56 110 255   8\n",
            "   4  24   1 121  42   6  31  55   8   4 256  16   1  12 257  23 258  80\n",
            " 111  10   3  24  25   6   1 143  73   9  47   5 120   4  24  42   6 143\n",
            "  73  14  39  81  49   2  24  15   1 259  45   8 134  92  41  52   7   5\n",
            "  78   6  21  13  11 144 145  41  52   7   4 260  92  41  52 261  46 262\n",
            "  41 146  32  27 263 146   2 264 265  66  15  92 266 107 267 268  32  22\n",
            "   2  56 269   4  37  21  12 141  15 270   3  23 271   2   9  19 272  76\n",
            "   7  11 144 145  41  52 274  17 276  17 116 277 278  18 280 281 282]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(tokenizer.word_index)+1)\n",
        "#as the one hot encoding starts from 0 thats why we used tokenizer.word_index"
      ],
      "metadata": {
        "id": "WC588RV_l8-T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3l0-P7Mu0SY",
        "outputId": "d074e808-3bc1-4795-adb1-899e5affd03a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7JpUJLmpkK3",
        "outputId": "62de2677-bc37-46b0-efd0-828fe9cf9fcf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below the starting of the index starts with 0 but we dont have anything like that in our word_index we just use it because one hot encoding starts from 0"
      ],
      "metadata": {
        "id": "cWg244mdp8OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbJMskcEp44S",
        "outputId": "8255f4b0-d94e-4887-cbfa-292c0ba2cf33"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTA081D-ucWU",
        "outputId": "b5efa13b-75a9-4c72-c3df-3ec38695af9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJszn84Rp6_4",
        "outputId": "390f453d-97f5-4956-a05a-6a21dbd8ef4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  93],\n",
              "       [  0,   0,   0, ...,   0,  93,   1],\n",
              "       [  0,   0,   0, ...,   0,   0,  11],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0, 279,  18],\n",
              "       [  0,   0,   0, ..., 279,  18, 280],\n",
              "       [  0,   0,   0, ...,  18, 280, 281]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "1chqvbp-qo9S"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=283,output_dim=100,input_length=56))\n",
        "#input_dim = vocabulary size\n",
        "#Size of each word’s embedding vector\n",
        "#Length of each input sequence (number of tokens per sentence).\n",
        "\n",
        "#If a sentence has fewer than 56 words → it’s padded with zeros.\n",
        "\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(283,activation='softmax'))\n",
        "model.build(input_shape=(None,56))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "zDxIqOPtqz-O",
        "outputId": "acd7155a-8154-45c4-f686-6ad4a518748a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m28,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m)            │        \u001b[38;5;34m42,733\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,733</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221,633\u001b[0m (865.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,633</span> (865.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221,633\u001b[0m (865.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,633</span> (865.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-eoSq8tJrMf1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSjp9Z8jrjpC",
        "outputId": "bfa8af58-d6f9-42cc-ea14-69e4325f9f7c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.0513 - loss: 5.5596\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0657 - loss: 5.1021\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0807 - loss: 5.0106\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0850 - loss: 4.9227\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0794 - loss: 4.8971\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0881 - loss: 4.7681\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0822 - loss: 4.7195\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1298 - loss: 4.4181\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1607 - loss: 4.2278\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1756 - loss: 4.0736\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2103 - loss: 3.8300\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2331 - loss: 3.6319\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2996 - loss: 3.3752\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3263 - loss: 3.0864\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3865 - loss: 2.9043\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3912 - loss: 2.7743\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4401 - loss: 2.5816\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4706 - loss: 2.4245\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: 2.2016\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5459 - loss: 2.1303\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6132 - loss: 1.9017\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6484 - loss: 1.7900\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6579 - loss: 1.6851\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7044 - loss: 1.5567\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7122 - loss: 1.3902\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7065 - loss: 1.4183\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 1.2280\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 1.1360\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8253 - loss: 1.0974\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8371 - loss: 1.0117\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8694 - loss: 0.9390\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8811 - loss: 0.9138\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8840 - loss: 0.8232\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9022 - loss: 0.7687\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9041 - loss: 0.7133\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9214 - loss: 0.6560\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9305 - loss: 0.6285\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9144 - loss: 0.6216\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.5701\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9373 - loss: 0.5237\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.4985\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 0.4623\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9318 - loss: 0.4584\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9347 - loss: 0.4413\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.3876\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9444 - loss: 0.3890\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.3731\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.3436\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.3513\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.3423\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.3162\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9366 - loss: 0.3216\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.2763\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 0.2712\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.2739\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.2653\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.2645\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9479 - loss: 0.2650\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9525 - loss: 0.2271\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9606 - loss: 0.2103\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.2246\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.2024\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.2194\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.2032\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.2176\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.1963\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9506 - loss: 0.1952\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.1946\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2112\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1690\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9509 - loss: 0.1708\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.1860\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9617 - loss: 0.1615\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.1470\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.1774\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1648\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9528 - loss: 0.1523\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9580 - loss: 0.1426\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9385 - loss: 0.1707\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9520 - loss: 0.1462\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.1451\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1534\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9420 - loss: 0.1561\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9456 - loss: 0.1529\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9514 - loss: 0.1481\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9568 - loss: 0.1373\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9420 - loss: 0.1448\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.1410\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9588 - loss: 0.1338\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.1315\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1519\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9467 - loss: 0.1312\n",
            "Epoch 93/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1313\n",
            "Epoch 94/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1344\n",
            "Epoch 95/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9442 - loss: 0.1350\n",
            "Epoch 96/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.1322\n",
            "Epoch 97/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.1284\n",
            "Epoch 98/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.1149\n",
            "Epoch 99/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.1246\n",
            "Epoch 100/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e170c850bc0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4ykqIhClvh-k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text='mail'\n",
        "for i in range(10):\n",
        "\n",
        "  #tokenize padding predict\n",
        "  token_text=tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_token_text=pad_sequences([token_text],maxlen=56,padding='pre')\n",
        "  print(padded_token_text)\n",
        "\n",
        "  pos=np.argmax(model.predict(padded_token_text))\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      text=text+' '+word\n",
        "      print(text)\n",
        "      time.sleep(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVruoerssvQz",
        "outputId": "39404421-02c6-401b-b715-ce7a4ea6ab4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0 61]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "mail this\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0 61 21]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "mail this google\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0 61 21 58]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "mail this google sheet\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  61  21\n",
            "   58 176]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "mail this google sheet to\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  61  21  58\n",
            "  176   4]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "mail this google sheet to see\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0  61  21  58 176\n",
            "    4  79]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "mail this google sheet to see month\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0  61  21  58 176   4\n",
            "   79  45]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "mail this google sheet to see month by\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0  61  21  58 176   4  79\n",
            "   45  59]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "mail this google sheet to see month by month\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0  61  21  58 176   4  79  45\n",
            "   59  45]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "mail this google sheet to see month by month time\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0  61  21  58 176   4  79  45  59\n",
            "   45 109]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "mail this google sheet to see month by month time table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mKq_y4CUtaD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "an_W5Z0otLoZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIgUrn15tRLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLxPwG4vtUd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}